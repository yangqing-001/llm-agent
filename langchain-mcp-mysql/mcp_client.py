import asyncio
import sys
import os
from dotenv import load_dotenv
from langchain.memory import ConversationBufferWindowMemory
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from pydantic import SecretStr

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– ChatOpenAI å¤§æ¨¡å‹å®¢æˆ·ç«¯
llm = ChatOpenAI(
    model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),  # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åç§°
    api_key=SecretStr(os.getenv("OPENAI_API_KEY", "")),  # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),  # ä»ç¯å¢ƒå˜é‡è·å–åŸºç¡€URL
    temperature=float(os.getenv("TEMPERATURE", "0.7"))  # ä»ç¯å¢ƒå˜é‡è·å–æ¸©åº¦å€¼
)


# åˆ›å»ºä¼˜åŒ–çš„æç¤ºè¯
def create_smart_prompt():
    """åˆ›å»ºæ™ºèƒ½æç¤ºè¯ï¼Œå¼•å¯¼AIåˆç†ä½¿ç”¨å·¥å…·"""
    system_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„MySQLæ•°æ®åº“ç®¡ç†åŠ©æ‰‹ï¼Œå…·å¤‡å®Œæ•´çš„MySQLæ•°æ®åº“æ“ä½œèƒ½åŠ›ã€‚

ğŸ”§ å¯ç”¨å·¥å…·åŠä½¿ç”¨åœºæ™¯ï¼š

ğŸ“Š æ•°æ®åº“å’Œè¡¨ç®¡ç†ï¼š
- create_database: åˆ›å»ºæ–°çš„MySQLæ•°æ®åº“
- show_databases: æ˜¾ç¤ºæ‰€æœ‰æ•°æ®åº“
- create_table: åœ¨æŒ‡å®šæ•°æ®åº“ä¸­åˆ›å»ºæ–°è¡¨
- show_tables: æ˜¾ç¤ºæŒ‡å®šæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨

ğŸ” è¡¨ç»“æ„æŸ¥è¯¢ï¼ˆé‡è¦ï¼ï¼‰ï¼š
- describe_table: æŸ¥çœ‹è¡¨çš„è¯¦ç»†ç»“æ„ï¼ˆå­—æ®µåã€ç±»å‹ã€çº¦æŸã€é»˜è®¤å€¼ç­‰ï¼‰
- show_table_indexes: æ˜¾ç¤ºè¡¨çš„ç´¢å¼•ä¿¡æ¯
- show_create_table: æ˜¾ç¤ºåˆ›å»ºè¡¨çš„å®Œæ•´SQLè¯­å¥

ğŸ“ æ•°æ®æ“ä½œï¼š
- insert_data: å‘è¡¨ä¸­æ’å…¥æ•°æ®
- update_data: æ›´æ–°è¡¨ä¸­çš„æ•°æ®
- delete_data: åˆ é™¤è¡¨ä¸­çš„æ•°æ®
- query_data: æŸ¥è¯¢è¡¨ä¸­çš„æ•°æ®

ğŸ¯ è¡¨è®¾è®¡åˆ†æï¼ˆæ–°åŠŸèƒ½ï¼ï¼‰ï¼š
- analyze_table_design: å…¨é¢åˆ†æè¡¨è®¾è®¡ï¼Œæä¾›ä¸“ä¸šè¯„åˆ¤å’Œä¼˜åŒ–å»ºè®®
- get_table_structure_info: è·å–è¡¨çš„å®Œæ•´ç»“æ„ä¿¡æ¯ï¼ˆå­—æ®µã€ç´¢å¼•ã€çŠ¶æ€ç­‰ï¼‰
- check_table_performance_issues: æ£€æŸ¥è¡¨çš„æ€§èƒ½é—®é¢˜å¹¶æä¾›ä¼˜åŒ–å»ºè®®

ğŸ¯ æ™ºèƒ½æ“ä½œæµç¨‹ï¼ˆå¿…é¡»éµå¾ªï¼‰ï¼š

1. ğŸ“‹ æ•°æ®æ“ä½œå‰çš„å‡†å¤‡å·¥ä½œï¼š
   - åœ¨è¿›è¡Œä»»ä½•æ•°æ®æ’å…¥ã€æ›´æ–°ã€åˆ é™¤æ“ä½œä¹‹å‰ï¼Œå¿…é¡»å…ˆä½¿ç”¨ describe_table æŸ¥çœ‹è¡¨ç»“æ„
   - äº†è§£å­—æ®µåç§°ã€æ•°æ®ç±»å‹ã€æ˜¯å¦å…è®¸NULLã€é»˜è®¤å€¼ç­‰ä¿¡æ¯
   - ç¡®ä¿æ“ä½œçš„æ•°æ®ç¬¦åˆè¡¨ç»“æ„è¦æ±‚

2. ğŸ” è¡¨ç»“æ„åˆ†æï¼š
   - æ£€æŸ¥å­—æ®µçš„æ•°æ®ç±»å‹ï¼ˆINTã€VARCHARã€DATEç­‰ï¼‰
   - æ³¨æ„å­—æ®µé•¿åº¦é™åˆ¶ï¼ˆå¦‚VARCHAR(100)ï¼‰
   - è¯†åˆ«ä¸»é”®ã€å¤–é”®ã€å”¯ä¸€çº¦æŸ
   - äº†è§£å“ªäº›å­—æ®µä¸èƒ½ä¸ºNULL
   - æŸ¥çœ‹æ˜¯å¦æœ‰AUTO_INCREMENTå­—æ®µ

3. ğŸ“Š æ•°æ®éªŒè¯ï¼š
   - ç¡®ä¿æ’å…¥çš„æ•°æ®ç±»å‹ä¸å­—æ®µç±»å‹åŒ¹é…
   - æ£€æŸ¥å­—ç¬¦ä¸²é•¿åº¦ä¸è¶…è¿‡å­—æ®µé™åˆ¶
   - éªŒè¯å¿…å¡«å­—æ®µéƒ½æœ‰å€¼
   - å¯¹äºAUTO_INCREMENTå­—æ®µï¼Œé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šå€¼

4. ğŸ›¡ï¸ å®‰å…¨æ“ä½œï¼š
   - æ›´æ–°å’Œåˆ é™¤æ“ä½œå¿…é¡»æœ‰æ˜ç¡®çš„WHEREæ¡ä»¶
   - é¿å…æ— æ¡ä»¶çš„UPDATEæˆ–DELETEæ“ä½œ
   - åœ¨æ‰§è¡Œå±é™©æ“ä½œå‰ï¼Œå…ˆç”¨SELECTéªŒè¯æ¡ä»¶

ğŸ’¡ æœ€ä½³å®è·µç¤ºä¾‹ï¼š

ç”¨æˆ·è¯´ï¼š"å‘å‘˜å·¥è¡¨æ’å…¥ä¸€ä¸ªæ–°å‘˜å·¥"
æ­£ç¡®æµç¨‹ï¼š
1. å…ˆæ‰§è¡Œï¼šdescribe_table("company", "employees")
2. åˆ†æè¡¨ç»“æ„ï¼Œäº†è§£å­—æ®µè¦æ±‚
3. æ ¹æ®è¡¨ç»“æ„æ„é€ æ­£ç¡®çš„JSONæ•°æ®
4. æ‰§è¡Œæ’å…¥æ“ä½œ

æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼š
ğŸ¯ å·¥å…·ä½¿ç”¨åŸåˆ™ï¼š
1. æ•°æ®æ“ä½œå‰å¿…é¡»å…ˆæŸ¥çœ‹è¡¨ç»“æ„ - è¿™æ˜¯æœ€é‡è¦çš„åŸåˆ™ï¼
2. å¯¹äºä¸€èˆ¬æ€§MySQLçŸ¥è¯†é—®ç­”ï¼Œç›´æ¥å›ç­”ï¼Œæ— éœ€è°ƒç”¨å·¥å…·
3. æ‰§è¡Œæ“ä½œå‰ï¼Œç¡®ä¿å®Œå…¨ç†è§£ç”¨æˆ·éœ€æ±‚å’Œè¡¨ç»“æ„
4. å¦‚æœæ“ä½œå¤±è´¥ï¼Œåˆ†æé”™è¯¯åŸå› å¹¶æä¾›å…·ä½“çš„ä¿®æ­£å»ºè®®
5. å§‹ç»ˆæä¾›æ¸…æ™°çš„æ“ä½œæ­¥éª¤è¯´æ˜

ğŸ” è¡¨è®¾è®¡åˆ†æä½¿ç”¨åœºæ™¯ï¼š
- å½“ç”¨æˆ·è¯¢é—®è¡¨è®¾è®¡æ˜¯å¦åˆç†æ—¶ï¼Œä½¿ç”¨ analyze_table_design
- å½“ç”¨æˆ·éœ€è¦è¡¨çš„å®Œæ•´ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨ get_table_structure_info
- å½“ç”¨æˆ·å…³å¿ƒè¡¨æ€§èƒ½æ—¶ï¼Œä½¿ç”¨ check_table_performance_issues
- è¡¨è®¾è®¡åˆ†æä¼šæ£€æŸ¥å‘½åè§„èŒƒã€æ•°æ®ç±»å‹ã€ç´¢å¼•è®¾è®¡ç­‰å¤šä¸ªç»´åº¦

è¯·ä¿æŒä¸“ä¸šã€å‹å¥½çš„å¯¹è¯é£æ ¼ï¼Œå¸®åŠ©ç”¨æˆ·é«˜æ•ˆã€å®‰å…¨åœ°ç®¡ç†MySQLæ•°æ®åº“ã€‚"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        MessagesPlaceholder(variable_name="messages")
    ])
    
    return prompt

# ç®€åŒ–çš„ç»“æœè¾“å‡ºå‡½æ•°
def print_result(agent_response):
    """è¾“å‡ºä»£ç†å“åº”ç»“æœ"""
    messages = agent_response.get("messages", [])
    
    # æå–æœ€ç»ˆç­”æ¡ˆ
    for message in reversed(messages):
        if message.type == "ai" and message.content:
            print(f"\nğŸ¯ å›ç­”: {message.content}")
            break

# ä¸»å‡½æ•°
async def main():
    """
    ä¸»å‡½æ•° - é›†æˆLangChainè®°å¿†åŠŸèƒ½çš„å¯¹è¯å®¢æˆ·ç«¯
    
    Author: FangGL
    Date: 2024-12-19
    """
    client = None
    
    try:
        # åˆå§‹åŒ–MCPå®¢æˆ·ç«¯ - MySQLæ•°æ®åº“æ§åˆ¶æœåŠ¡å™¨å’Œè¡¨è®¾è®¡åˆ†ææœåŠ¡å™¨
        client = MultiServerMCPClient({  # type: ignore
            "mysql": {
                "command": "python3",
                "args": ["./mcp_servers/mysql_server.py"],
                "transport": "stdio",
            },
            "table_analyzer": {
                "command": "python3",
                "args": ["./mcp_servers/table_design_analyzer.py"],
                "transport": "stdio",
            }
        })

        tools = await client.get_tools()
        
        # åˆ›å»ºå¸¦æœ‰æ™ºèƒ½æç¤ºè¯çš„ä»£ç†
        smart_prompt = create_smart_prompt()
        agent = create_react_agent(llm, tools, prompt=smart_prompt)

        # ä½¿ç”¨çª—å£è®°å¿† - ä»ç¯å¢ƒå˜é‡è·å–çª—å£å¤§å°ï¼Œæ— éœ€transformersåŒ…
        memory_window_size = int(os.getenv("MEMORY_WINDOW_SIZE", "10"))
        memory = ConversationBufferWindowMemory(
            k=memory_window_size,    # ä¿ç•™æœ€è¿‘Nè½®å¯¹è¯
            return_messages=True     # è¿”å›æ¶ˆæ¯å¯¹è±¡
        )

        print("âœ¨ MySQLæ•°æ®åº“ç®¡ç†åŠ©æ‰‹å·²å¯åŠ¨!")
        print("ğŸ—„ï¸ æ•°æ®åº“è¿æ¥: 127.0.0.1:3306 (root)")
        print("ğŸ”§ æ ¸å¿ƒåŠŸèƒ½: åˆ›å»ºæ•°æ®åº“ | åˆ›å»ºè¡¨ | æ•°æ®å¢åˆ æ”¹æŸ¥ | æŸ¥çœ‹æ•°æ®åº“/è¡¨")
        print("ğŸ” è¡¨ç»“æ„åŠŸèƒ½: æŸ¥çœ‹è¡¨ç»“æ„ | æ˜¾ç¤ºç´¢å¼•ä¿¡æ¯ | æŸ¥çœ‹å»ºè¡¨è¯­å¥")
        print("ğŸ¯ è¡¨è®¾è®¡åˆ†æ: è®¾è®¡è¯„åˆ¤ | æ€§èƒ½åˆ†æ | ä¼˜åŒ–å»ºè®® (æ–°åŠŸèƒ½!)")
        print("ğŸ§  AIä¼šæ™ºèƒ½åˆ¤æ–­ä½•æ—¶éœ€è¦è°ƒç”¨æ•°æ®åº“å·¥å…·")
        print("ğŸ“‹ é‡è¦æç¤º: AIä¼šåœ¨æ•°æ®æ“ä½œå‰è‡ªåŠ¨æŸ¥çœ‹è¡¨ç»“æ„ï¼Œç¡®ä¿æ“ä½œå®‰å…¨")
        print("ğŸ’¬ æ”¯æŒæµå¼å¯¹è¯ï¼Œä½“éªŒæ›´è‡ªç„¶")
        print("è¾“å…¥ 'exit' é€€å‡º\n")

        # å¯¹è¯å¾ªç¯
        while True:
            user_input = input("ğŸ’¬ é—®é¢˜: ").strip()
            
            if user_input.lower() == "exit":
                print("ğŸ‘‹ å†è§!")
                break
            
            if not user_input:
                continue
            
            # è·å–å†å²æ¶ˆæ¯å¹¶æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages = memory.chat_memory.messages.copy()
            messages.append(HumanMessage(content=user_input))
            
            # å…ˆç”¨LLMåˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
            print("ğŸ¤” åˆ†æé—®é¢˜ä¸­...")
            
            # åˆ›å»ºåˆ¤æ–­æç¤º
            judge_prompt = f"""
            ç”¨æˆ·é—®é¢˜: {user_input}
            
            è¯·åˆ¤æ–­è¿™ä¸ªé—®é¢˜æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚
            
            éœ€è¦è°ƒç”¨å·¥å…·çš„æƒ…å†µ(å›ç­”YES)ï¼š
            - åˆ›å»ºMySQLæ•°æ®åº“æˆ–è¡¨
            - æ’å…¥ã€æ›´æ–°ã€åˆ é™¤æ•°æ®åº“ä¸­çš„æ•°æ®
            - æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æ•°æ®
            - æŸ¥çœ‹æ•°æ®åº“åˆ—è¡¨æˆ–è¡¨åˆ—è¡¨
            - æŸ¥çœ‹è¡¨ç»“æ„ã€å­—æ®µä¿¡æ¯ã€ç´¢å¼•ä¿¡æ¯
            - æ˜¾ç¤ºå»ºè¡¨è¯­å¥
            - å…¶ä»–éœ€è¦å®é™…æ“ä½œMySQLæ•°æ®åº“çš„ä»»åŠ¡
            
            ä¸éœ€è¦å·¥å…·çš„æƒ…å†µ(å›ç­”NO)ï¼š
            - ä¸€èˆ¬æ€§å¯¹è¯ã€é—®å€™ã€é—²èŠ
            - MySQLæ¦‚å¿µè§£é‡Šã€çŸ¥è¯†é—®ç­”
            - SQLè¯­æ³•å’¨è¯¢ã€å»ºè®®äº¤æµ
            - æ•°æ®åº“è®¾è®¡å»ºè®®
            - ç®€å•çš„ç†è®ºæ€§é—®é¢˜
            
            åªå›ç­”YESæˆ–NOï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
            """
            
            judge_response = await llm.ainvoke([HumanMessage(content=judge_prompt)])
            need_tools = "YES" in str(judge_response.content).upper()
            
            if need_tools:
                print("ğŸ”§ æ£€æµ‹åˆ°éœ€è¦å·¥å…·è°ƒç”¨ï¼Œå¯åŠ¨å¢å¼ºæ¨¡å¼...")
                ai_response = ""
                tool_used = False
                
                # ä½¿ç”¨agentå¤„ç†å·¥å…·è°ƒç”¨
                async for chunk in agent.astream({"messages": messages}):
                    for node_name, node_output in chunk.items():
                        if node_name == "agent":
                            messages_in_chunk = node_output.get("messages", [])
                            for msg in messages_in_chunk:
                                if msg.type == "ai":
                                    if hasattr(msg, "tool_calls") and msg.tool_calls:
                                        tool_used = True
                                        for tool_call in msg.tool_calls:
                                            print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}")
                                            print(f"ğŸ“ å‚æ•°: {tool_call['args']}")
                                    elif msg.content:
                                        ai_response = msg.content
                        
                        elif node_name == "tools":
                            messages_in_chunk = node_output.get("messages", [])
                            for msg in messages_in_chunk:
                                if msg.type == "tool":
                                    print(f"âœ… å·¥å…· '{msg.name}' æ‰§è¡Œå®Œæˆ")
                                    try:
                                        import json
                                        result = json.loads(msg.content) if isinstance(msg.content, str) else msg.content
                                        if isinstance(result, dict):
                                            if result.get("success"):
                                                stdout = result.get("stdout", "").strip()
                                                if stdout:
                                                    print(f"ğŸ“„ å‘½ä»¤è¾“å‡º:\n{stdout}")
                                            else:
                                                stderr = result.get("stderr", "")
                                                print(f"âŒ é”™è¯¯: {stderr}")
                                    except:
                                        print(f"ğŸ“„ åŸå§‹ç»“æœ: {msg.content}")
                
                if ai_response:
                    print(f"\nğŸ¯ æœ€ç»ˆå›ç­”: {ai_response}")
                    
            else:
                print("ğŸ’­ ä½¿ç”¨æµå¼å›ç­”æ¨¡å¼...")
                print("\nğŸ¯ AIå›ç­”: ", end="", flush=True)
                
                # ç›´æ¥ä½¿ç”¨LLMæµå¼ç”Ÿæˆ
                ai_response = ""
                async for chunk in llm.astream(messages):
                    if chunk.content:
                        content_str = str(chunk.content)
                        print(content_str, end="", flush=True)
                        ai_response += content_str
                
                print()  # æ¢è¡Œ
            
            # ä¿å­˜å¯¹è¯åˆ°è®°å¿†
            if ai_response:
                memory.save_context(
                    {"input": user_input},
                    {"output": str(ai_response)}
                )
                print("âœ“ å¯¹è¯å·²ä¿å­˜åˆ°è®°å¿†")
            else:
                print("âš ï¸ æœªè·å–åˆ°AIå›å¤")

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
